{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# √âpica 1: Ingesta - Sistema de Carga y Deduplicaci√≥n\n",
        "\n",
        "## Objetivo\n",
        "Validar el sistema de ingesta de documentos con deduplicaci√≥n SHA256, carga por lotes y descarga gen√©rica por URL.\n",
        "\n",
        "## Tickets cubiertos\n",
        "| Ticket | Descripci√≥n | Estado |\n",
        "|--------|-------------|--------|\n",
        "| 1.1 | Implementar deduplicaci√≥n por SHA256 en upload | ‚úÖ |\n",
        "| 1.2 | Implementar batch upload (subir m√∫ltiples archivos) | ‚úÖ |\n",
        "| 1.3 | Implementar descarga gen√©rica por URL | ‚úÖ |\n",
        "\n",
        "## Componentes principales implementados\n",
        "- `hash_utils.py` ‚Äî Utilidades de hashing SHA256\n",
        "- `upload.py` ‚Äî Endpoints de carga y descarga\n",
        "- `models.py` ‚Äî Columnas file_hash y file_size_bytes\n",
        "- `crud.py` ‚Äî L√≥gica de deduplicaci√≥n\n",
        "- `pds_prov.py` ‚Äî Scraper con c√°lculo de hash\n",
        "- `backfill_file_hashes.py` ‚Äî Script de backfill\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Setup del entorno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Backend path agregado: /Users/germanevangelisti/watcher-agent/watcher-monolith/backend\n",
            "‚úÖ Python: 3.9.10 (main, Oct 11 2024, 16:02:49) \n",
            "[Clang 15.0.0 (clang-1500.3.9.4)]\n",
            "‚úÖ Working directory: /Users/germanevangelisti/watcher-agent/notebooks\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Agregar paths necesarios\n",
        "backend_path = Path.cwd().parent / \"watcher-monolith\" / \"backend\"\n",
        "sys.path.insert(0, str(backend_path))\n",
        "\n",
        "print(f\"‚úÖ Backend path agregado: {backend_path}\")\n",
        "print(f\"‚úÖ Python: {sys.version}\")\n",
        "print(f\"‚úÖ Working directory: {Path.cwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Imports completados\n"
          ]
        }
      ],
      "source": [
        "# Imports necesarios\n",
        "import asyncio\n",
        "import httpx\n",
        "from datetime import datetime\n",
        "from sqlalchemy import select, func\n",
        "\n",
        "# Imports del proyecto\n",
        "from app.services.hash_utils import compute_sha256, compute_sha256_bytes, verify_file_hash\n",
        "from app.db.database import AsyncSessionLocal\n",
        "from app.db.models import Boletin\n",
        "from app.db import crud\n",
        "from app.core.config import settings\n",
        "\n",
        "print(\"‚úÖ Imports completados\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Task 1.1: SHA256 Deduplication\n",
        "\n",
        "### Objetivos\n",
        "- ‚úÖ Verificar que las columnas `file_hash` y `file_size_bytes` existan en la tabla `boletines`\n",
        "- ‚úÖ Probar funciones de hashing (`compute_sha256`, `compute_sha256_bytes`)\n",
        "- ‚úÖ Validar la l√≥gica de deduplicaci√≥n en `create_boletin()`\n",
        "- ‚úÖ Verificar que el scraper calcula hashes autom√°ticamente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1.1 - Verificar esquema de BD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Verificaci√≥n de esquema:\n",
            "  ‚Ä¢ Columna 'file_hash': ‚úÖ\n",
            "  ‚Ä¢ Columna 'file_size_bytes': ‚úÖ\n",
            "\n",
            "‚úÖ Migraci√≥n de BD exitosa\n"
          ]
        }
      ],
      "source": [
        "# Verificar que las columnas existen en la BD\n",
        "async def verify_schema():\n",
        "    async with AsyncSessionLocal() as db:\n",
        "        # Obtener un boletin de ejemplo\n",
        "        query = select(Boletin).limit(1)\n",
        "        result = await db.execute(query)\n",
        "        boletin = result.scalar_one_or_none()\n",
        "        \n",
        "        if boletin:\n",
        "            # Verificar atributos\n",
        "            has_file_hash = hasattr(boletin, 'file_hash')\n",
        "            has_file_size = hasattr(boletin, 'file_size_bytes')\n",
        "            \n",
        "            print(\"üìä Verificaci√≥n de esquema:\")\n",
        "            print(f\"  ‚Ä¢ Columna 'file_hash': {'‚úÖ' if has_file_hash else '‚ùå'}\")\n",
        "            print(f\"  ‚Ä¢ Columna 'file_size_bytes': {'‚úÖ' if has_file_size else '‚ùå'}\")\n",
        "            \n",
        "            if boletin.file_hash:\n",
        "                print(f\"\\n  Ejemplo de hash: {boletin.file_hash[:16]}...\")\n",
        "                print(f\"  Tama√±o: {boletin.file_size_bytes} bytes\")\n",
        "            \n",
        "            return has_file_hash and has_file_size\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  No hay boletines en la BD para verificar\")\n",
        "            return None\n",
        "\n",
        "result = await verify_schema()\n",
        "if result:\n",
        "    print(\"\\n‚úÖ Migraci√≥n de BD exitosa\")\n",
        "elif result is None:\n",
        "    print(\"\\n‚ö†Ô∏è  BD vac√≠a, pero esquema debe estar correcto\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Error en migraci√≥n de BD\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1.2 - Probar funciones de hashing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Test 1: compute_sha256_bytes()\n",
            "  Content: Este es un contenido de prueba para Epic 1\n",
            "  Hash: b8589f04d718c1a7301481e5dfbfca8574400a57b06b725dd8e49593abc07829\n",
            "  Longitud: 64 caracteres\n",
            "  ‚úÖ Hash consistente\n",
            "  ‚úÖ Hash diferente para contenido diferente\n"
          ]
        }
      ],
      "source": [
        "# Test 1: compute_sha256_bytes\n",
        "test_content = b\"Este es un contenido de prueba para Epic 1\"\n",
        "hash1 = compute_sha256_bytes(test_content)\n",
        "\n",
        "print(\"üß™ Test 1: compute_sha256_bytes()\")\n",
        "print(f\"  Content: {test_content.decode()}\")\n",
        "print(f\"  Hash: {hash1}\")\n",
        "print(f\"  Longitud: {len(hash1)} caracteres\")\n",
        "\n",
        "# Validar que es consistente\n",
        "hash2 = compute_sha256_bytes(test_content)\n",
        "assert hash1 == hash2, \"Hash debe ser consistente\"\n",
        "print(\"  ‚úÖ Hash consistente\")\n",
        "\n",
        "# Validar que contenido diferente produce hash diferente\n",
        "hash3 = compute_sha256_bytes(b\"Contenido diferente\")\n",
        "assert hash1 != hash3, \"Contenido diferente debe producir hash diferente\"\n",
        "print(\"  ‚úÖ Hash diferente para contenido diferente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß™ Test 2: compute_sha256() en archivos reales\n",
            "\n",
            "  üìÑ 20250327_2_Secc.pdf\n",
            "     Hash: 5c699f470f6bbe8bba1bf55e3c638b64...\n",
            "     Tama√±o: 1,257,816 bytes\n",
            "     Verificaci√≥n: ‚úÖ\n",
            "\n",
            "  üìÑ 20250306_5_Secc.pdf\n",
            "     Hash: 32a6231b83ce9704dcc83c0a8415f14f...\n",
            "     Tama√±o: 677,271 bytes\n",
            "     Verificaci√≥n: ‚úÖ\n",
            "\n",
            "  üìÑ 20250306_4_Secc.pdf\n",
            "     Hash: 4a8eeb88285602599d5d922d2cb8e467...\n",
            "     Tama√±o: 2,705,337 bytes\n",
            "     Verificaci√≥n: ‚úÖ\n"
          ]
        }
      ],
      "source": [
        "# Test 2: compute_sha256 (archivo)\n",
        "# Buscar un PDF de ejemplo\n",
        "boletines_dir = Path(\"/Users/germanevangelisti/watcher-agent/boletines\")\n",
        "sample_pdfs = list(boletines_dir.rglob(\"*.pdf\"))[:3]  # Primeros 3 PDFs\n",
        "\n",
        "if sample_pdfs:\n",
        "    print(\"\\nüß™ Test 2: compute_sha256() en archivos reales\")\n",
        "    for pdf_path in sample_pdfs:\n",
        "        try:\n",
        "            file_hash = compute_sha256(pdf_path)\n",
        "            file_size = pdf_path.stat().st_size\n",
        "            \n",
        "            print(f\"\\n  üìÑ {pdf_path.name}\")\n",
        "            print(f\"     Hash: {file_hash[:32]}...\")\n",
        "            print(f\"     Tama√±o: {file_size:,} bytes\")\n",
        "            \n",
        "            # Verificar hash\n",
        "            is_valid = verify_file_hash(pdf_path, file_hash)\n",
        "            print(f\"     Verificaci√≥n: {'‚úÖ' if is_valid else '‚ùå'}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"     ‚ùå Error: {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No se encontraron PDFs de ejemplo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1.3 - Probar deduplicaci√≥n en CRUD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Test 3: Deduplicaci√≥n por hash\n",
            "\n",
            "  ‚úÖ Primer registro creado: ID=1311, filename=test_file_1.pdf\n",
            "     Hash: test_hash_20260210140005\n",
            "\n",
            "  üìã Segundo intento de creaci√≥n:\n",
            "     ID retornado: 1311\n",
            "     Filename: test_file_1.pdf\n",
            "     ‚úÖ DEDUPLICACI√ìN EXITOSA: Retorn√≥ registro existente\n",
            "\n",
            "  üßπ Registros de prueba eliminados\n",
            "\n",
            "‚úÖ Sistema de deduplicaci√≥n funciona correctamente\n"
          ]
        }
      ],
      "source": [
        "# Test de deduplicaci√≥n\n",
        "async def test_deduplication():\n",
        "    test_hash = \"test_hash_\" + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    \n",
        "    async with AsyncSessionLocal() as db:\n",
        "        print(\"üß™ Test 3: Deduplicaci√≥n por hash\")\n",
        "        \n",
        "        # Crear primer registro\n",
        "        boletin1 = await crud.create_boletin(\n",
        "            db=db,\n",
        "            filename=\"test_file_1.pdf\",\n",
        "            date=\"20250210\",\n",
        "            section=\"1\",\n",
        "            status=\"pending\",\n",
        "            file_hash=test_hash,\n",
        "            file_size_bytes=12345\n",
        "        )\n",
        "        await db.commit()\n",
        "        \n",
        "        print(f\"\\n  ‚úÖ Primer registro creado: ID={boletin1.id}, filename={boletin1.filename}\")\n",
        "        print(f\"     Hash: {boletin1.file_hash}\")\n",
        "        \n",
        "        # Intentar crear segundo registro con mismo hash pero diferente filename\n",
        "        boletin2 = await crud.create_boletin(\n",
        "            db=db,\n",
        "            filename=\"test_file_2_DIFERENTE.pdf\",  # Nombre diferente\n",
        "            date=\"20250211\",\n",
        "            section=\"2\",\n",
        "            status=\"pending\",\n",
        "            file_hash=test_hash,  # MISMO HASH\n",
        "            file_size_bytes=12345\n",
        "        )\n",
        "        await db.commit()\n",
        "        \n",
        "        print(f\"\\n  üìã Segundo intento de creaci√≥n:\")\n",
        "        print(f\"     ID retornado: {boletin2.id}\")\n",
        "        print(f\"     Filename: {boletin2.filename}\")\n",
        "        \n",
        "        if boletin1.id == boletin2.id:\n",
        "            print(f\"     ‚úÖ DEDUPLICACI√ìN EXITOSA: Retorn√≥ registro existente\")\n",
        "        else:\n",
        "            print(f\"     ‚ùå FALLO: Cre√≥ nuevo registro en lugar de deduplicar\")\n",
        "        \n",
        "        # Limpiar registros de prueba\n",
        "        await db.delete(boletin1)\n",
        "        await db.commit()\n",
        "        print(\"\\n  üßπ Registros de prueba eliminados\")\n",
        "        \n",
        "        return boletin1.id == boletin2.id\n",
        "\n",
        "dedup_works = await test_deduplication()\n",
        "if dedup_works:\n",
        "    print(\"\\n‚úÖ Sistema de deduplicaci√≥n funciona correctamente\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Error en sistema de deduplicaci√≥n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1.4 - Verificar scraper con hashes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Test 4: Scraper calcula hashes autom√°ticamente\n",
            "\n",
            "  üìÑ Archivo: 20250115_1_Secc.pdf\n",
            "  Status: exists\n",
            "  ‚úÖ Hash calculado: fcc152bcd97bb4a407ff2f6936af002f...\n",
            "  ‚úÖ Tama√±o: 519,080 bytes\n",
            "\n",
            "‚úÖ Scraper integrado con sistema de hashing\n"
          ]
        }
      ],
      "source": [
        "# Importar scraper\n",
        "from app.scrapers.pds_prov import create_provincial_scraper\n",
        "from app.scrapers.base_scraper import DocumentType\n",
        "from datetime import date\n",
        "\n",
        "# Test del scraper\n",
        "async def test_scraper_hash():\n",
        "    print(\"üß™ Test 4: Scraper calcula hashes autom√°ticamente\")\n",
        "    \n",
        "    scraper = create_provincial_scraper()\n",
        "    \n",
        "    # Intentar descargar un archivo (usar√° uno existente si ya est√° descargado)\n",
        "    target_date = date(2025, 1, 15)  # Fecha de ejemplo\n",
        "    \n",
        "    result = await scraper.download_single(\n",
        "        target_date=target_date,\n",
        "        document_type=DocumentType.BOLETIN,\n",
        "        section=1\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n  üìÑ Archivo: {result.filename}\")\n",
        "    print(f\"  Status: {result.status}\")\n",
        "    \n",
        "    if result.metadata and 'file_hash' in result.metadata:\n",
        "        print(f\"  ‚úÖ Hash calculado: {result.metadata['file_hash'][:32]}...\")\n",
        "        print(f\"  ‚úÖ Tama√±o: {result.metadata.get('file_size_bytes', 0):,} bytes\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"  ‚ùå Hash NO encontrado en metadata\")\n",
        "        return False\n",
        "\n",
        "scraper_ok = await test_scraper_hash()\n",
        "if scraper_ok:\n",
        "    print(\"\\n‚úÖ Scraper integrado con sistema de hashing\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Verificar integraci√≥n del scraper\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1.5 - Estad√≠sticas de hashes en BD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Estad√≠sticas de hashes en BD:\n",
            "\n",
            "  Total de boletines: 1,310\n",
            "  Con file_hash: 0 (0.0%)\n",
            "  Sin file_hash: 1,310 (100.0%)\n",
            "\n",
            "  üí° Ejecutar: python scripts/backfill_file_hashes.py\n",
            "\n",
            "  ‚úÖ No hay duplicados\n"
          ]
        }
      ],
      "source": [
        "# Estad√≠sticas de la BD\n",
        "async def hash_statistics():\n",
        "    async with AsyncSessionLocal() as db:\n",
        "        # Total de boletines\n",
        "        total = await db.scalar(select(func.count(Boletin.id)))\n",
        "        \n",
        "        # Con hash\n",
        "        with_hash = await db.scalar(\n",
        "            select(func.count(Boletin.id)).where(Boletin.file_hash.isnot(None))\n",
        "        )\n",
        "        \n",
        "        # Sin hash\n",
        "        without_hash = total - with_hash\n",
        "        \n",
        "        print(\"üìä Estad√≠sticas de hashes en BD:\")\n",
        "        print(f\"\\n  Total de boletines: {total:,}\")\n",
        "        print(f\"  Con file_hash: {with_hash:,} ({with_hash/total*100:.1f}%)\")\n",
        "        print(f\"  Sin file_hash: {without_hash:,} ({without_hash/total*100:.1f}%)\")\n",
        "        \n",
        "        if without_hash > 0:\n",
        "            print(f\"\\n  üí° Ejecutar: python scripts/backfill_file_hashes.py\")\n",
        "        \n",
        "        # Buscar duplicados\n",
        "        duplicates = await db.execute(\n",
        "            select(Boletin.file_hash, func.count(Boletin.id).label('count'))\n",
        "            .where(Boletin.file_hash.isnot(None))\n",
        "            .group_by(Boletin.file_hash)\n",
        "            .having(func.count(Boletin.id) > 1)\n",
        "        )\n",
        "        \n",
        "        dup_list = duplicates.all()\n",
        "        if dup_list:\n",
        "            print(f\"\\n  ‚ö†Ô∏è  Archivos duplicados detectados: {len(dup_list)}\")\n",
        "            for file_hash, count in dup_list[:5]:  # Primeros 5\n",
        "                print(f\"    ‚Ä¢ {file_hash[:16]}...: {count} copias\")\n",
        "        else:\n",
        "            print(f\"\\n  ‚úÖ No hay duplicados\")\n",
        "\n",
        "await hash_statistics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Task 1.2: Batch File Upload\n",
        "\n",
        "### Objetivos\n",
        "- ‚úÖ Probar endpoint `POST /api/v1/upload/files` con m√∫ltiples archivos\n",
        "- ‚úÖ Verificar validaci√≥n de PDFs (magic bytes)\n",
        "- ‚úÖ Verificar l√≠mites de tama√±o (10KB - 50MB)\n",
        "- ‚úÖ Verificar parsing de filename (YYYYMMDD_N_Secc.pdf)\n",
        "- ‚úÖ Verificar respuesta con detalles de cada archivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2.1 - Probar endpoint de upload (simulaci√≥n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Test 5: Parsing de filename\n",
            "\n",
            "  ‚úÖ 20250210_1_Secc.pdf\n",
            "     Valid: True\n",
            "     Date: 20250210\n",
            "     Section: 1\n",
            "\n",
            "  ‚úÖ 20241225_5_Secc.pdf\n",
            "     Valid: True\n",
            "     Date: 20241225\n",
            "     Section: 5\n",
            "\n",
            "  ‚úÖ documento.pdf\n",
            "     Valid: False\n",
            "\n",
            "  ‚úÖ 2025_1_Secc.pdf\n",
            "     Valid: False\n"
          ]
        }
      ],
      "source": [
        "# Importar m√≥dulo de upload\n",
        "from app.api.v1.endpoints.upload import (\n",
        "    parse_filename,\n",
        "    validate_pdf,\n",
        "    UploadResult,\n",
        "    BatchUploadResponse\n",
        ")\n",
        "\n",
        "# Test 1: Parsing de filename\n",
        "print(\"üß™ Test 5: Parsing de filename\")\n",
        "\n",
        "test_cases = [\n",
        "    (\"20250210_1_Secc.pdf\", True, \"20250210\", \"1\"),\n",
        "    (\"20241225_5_Secc.pdf\", True, \"20241225\", \"5\"),\n",
        "    (\"documento.pdf\", False, None, None),\n",
        "    (\"2025_1_Secc.pdf\", False, None, None),\n",
        "]\n",
        "\n",
        "for filename, should_be_valid, expected_date, expected_section in test_cases:\n",
        "    result = parse_filename(filename)\n",
        "    is_valid = result['valid']\n",
        "    \n",
        "    status = \"‚úÖ\" if is_valid == should_be_valid else \"‚ùå\"\n",
        "    print(f\"\\n  {status} {filename}\")\n",
        "    print(f\"     Valid: {is_valid}\")\n",
        "    if is_valid:\n",
        "        print(f\"     Date: {result['date']}\")\n",
        "        print(f\"     Section: {result['section']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß™ Test 6: Validaci√≥n de PDFs\n",
            "  ‚úÖ PDF v√°lido: True\n",
            "  ‚úÖ Archivo inv√°lido rechazado: True\n",
            "  ‚úÖ Archivo muy peque√±o rechazado: True\n"
          ]
        }
      ],
      "source": [
        "# Test 2: Validaci√≥n de PDF\n",
        "print(\"\\nüß™ Test 6: Validaci√≥n de PDFs\")\n",
        "\n",
        "# PDF v√°lido (magic bytes)\n",
        "valid_pdf = b\"%PDF-1.4\\n\" + b\"contenido...\"\n",
        "is_valid = validate_pdf(valid_pdf)\n",
        "print(f\"  {'‚úÖ' if is_valid else '‚ùå'} PDF v√°lido: {is_valid}\")\n",
        "\n",
        "# Archivo inv√°lido\n",
        "invalid_file = b\"Este no es un PDF\"\n",
        "is_valid = validate_pdf(invalid_file)\n",
        "print(f\"  {'‚úÖ' if not is_valid else '‚ùå'} Archivo inv√°lido rechazado: {not is_valid}\")\n",
        "\n",
        "# Archivo muy peque√±o\n",
        "tiny_file = b\"PDF\"\n",
        "is_valid = validate_pdf(tiny_file)\n",
        "print(f\"  {'‚úÖ' if not is_valid else '‚ùå'} Archivo muy peque√±o rechazado: {not is_valid}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2.2 - Test de endpoint real (requiere servidor corriendo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Test 7: Endpoint /upload/files\n",
            "  ‚úÖ Servidor corriendo\n",
            "  üì§ Subiendo: 20250327_2_Secc.pdf\n",
            "\n",
            "  ‚úÖ Upload exitoso\n",
            "     Total: 1\n",
            "     Uploaded: 1\n",
            "     Duplicates: 0\n",
            "     Failed: 0\n",
            "\n",
            "     üìÑ 20250327_2_Secc.pdf\n",
            "        Status: uploaded\n",
            "        Hash: 5c699f470f6bbe8bba1bf55e3c638b64...\n"
          ]
        }
      ],
      "source": [
        "# Test del endpoint real si el servidor est√° corriendo\n",
        "async def test_upload_endpoint():\n",
        "    base_url = \"http://localhost:8000/api/v1\"\n",
        "    \n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=10.0) as client:\n",
        "            # Verificar que el servidor est√° corriendo\n",
        "            health = await client.get(f\"{base_url}/agents/health\")\n",
        "            \n",
        "            if health.status_code == 200:\n",
        "                print(\"üß™ Test 7: Endpoint /upload/files\")\n",
        "                print(\"  ‚úÖ Servidor corriendo\")\n",
        "                \n",
        "                # Buscar un PDF peque√±o para test\n",
        "                sample_pdf = next(boletines_dir.rglob(\"*.pdf\"), None)\n",
        "                \n",
        "                if sample_pdf:\n",
        "                    print(f\"  üì§ Subiendo: {sample_pdf.name}\")\n",
        "                    \n",
        "                    files = {\"files\": (sample_pdf.name, open(sample_pdf, \"rb\"), \"application/pdf\")}\n",
        "                    \n",
        "                    response = await client.post(\n",
        "                        f\"{base_url}/upload/files\",\n",
        "                        files=files\n",
        "                    )\n",
        "                    \n",
        "                    if response.status_code == 200:\n",
        "                        data = response.json()\n",
        "                        print(f\"\\n  ‚úÖ Upload exitoso\")\n",
        "                        print(f\"     Total: {data['total']}\")\n",
        "                        print(f\"     Uploaded: {data['uploaded']}\")\n",
        "                        print(f\"     Duplicates: {data['duplicates']}\")\n",
        "                        print(f\"     Failed: {data['failed']}\")\n",
        "                        \n",
        "                        for result in data['results']:\n",
        "                            print(f\"\\n     üìÑ {result['filename']}\")\n",
        "                            print(f\"        Status: {result['status']}\")\n",
        "                            if result.get('file_hash'):\n",
        "                                print(f\"        Hash: {result['file_hash'][:32]}...\")\n",
        "                    else:\n",
        "                        print(f\"  ‚ùå Error: {response.status_code}\")\n",
        "                        print(f\"     {response.text}\")\n",
        "                else:\n",
        "                    print(\"  ‚ö†Ô∏è  No hay PDFs disponibles para test\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è  Servidor no responde en localhost:8000\")\n",
        "                print(\"   Para testear, iniciar backend con: cd watcher-monolith/backend && uvicorn app.main:app\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  No se pudo conectar al servidor: {e}\")\n",
        "        print(\"   Endpoint disponible pero servidor no est√° corriendo\")\n",
        "\n",
        "await test_upload_endpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Task 1.3: Generic URL Download\n",
        "\n",
        "### Objetivos\n",
        "- ‚úÖ Probar endpoint `POST /api/v1/upload/from-url` \n",
        "- ‚úÖ Probar endpoint `POST /api/v1/upload/from-urls` (batch)\n",
        "- ‚úÖ Verificar timeout y manejo de errores\n",
        "- ‚úÖ Verificar rate limiting en batch\n",
        "- ‚úÖ Verificar deduplicaci√≥n de URLs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3.1 - Test de descarga por URL (simulaci√≥n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Test 8: Descarga por URL\n",
            "  üì• URL: https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\n",
            "\n",
            "  ‚úÖ Descarga exitosa\n",
            "     Filename: 20250210_test_Secc.pdf\n",
            "     Status: uploaded\n",
            "     Boletin ID: 1311\n",
            "     Hash: 3df79d34abbca99308e79cb94461c189...\n"
          ]
        }
      ],
      "source": [
        "# Test de endpoint from-url\n",
        "async def test_url_download():\n",
        "    base_url = \"http://localhost:8000/api/v1\"\n",
        "    \n",
        "    # URL de ejemplo (PDF p√∫blico)\n",
        "    test_url = \"https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\"\n",
        "    \n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "            # Verificar servidor\n",
        "            health = await client.get(f\"{base_url}/agents/health\")\n",
        "            \n",
        "            if health.status_code == 200:\n",
        "                print(\"üß™ Test 8: Descarga por URL\")\n",
        "                print(f\"  üì• URL: {test_url}\")\n",
        "                \n",
        "                payload = {\n",
        "                    \"url\": test_url,\n",
        "                    \"filename\": \"20250210_test_Secc.pdf\",\n",
        "                    \"date\": \"20250210\",\n",
        "                    \"section\": \"1\",\n",
        "                    \"fuente\": \"provincial\"\n",
        "                }\n",
        "                \n",
        "                response = await client.post(\n",
        "                    f\"{base_url}/upload/from-url\",\n",
        "                    json=payload\n",
        "                )\n",
        "                \n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "                    print(f\"\\n  ‚úÖ Descarga exitosa\")\n",
        "                    print(f\"     Filename: {data['filename']}\")\n",
        "                    print(f\"     Status: {data['status']}\")\n",
        "                    print(f\"     Boletin ID: {data.get('boletin_id')}\")\n",
        "                    if data.get('file_hash'):\n",
        "                        print(f\"     Hash: {data['file_hash'][:32]}...\")\n",
        "                    if data.get('duplicate_of'):\n",
        "                        print(f\"     ‚ö†Ô∏è  Duplicado de: {data['duplicate_of']}\")\n",
        "                else:\n",
        "                    print(f\"  ‚ùå Error: {response.status_code}\")\n",
        "                    print(f\"     {response.text[:200]}\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è  Servidor no disponible\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error de conexi√≥n: {e}\")\n",
        "        print(\"   Endpoint disponible pero servidor no est√° corriendo\")\n",
        "\n",
        "await test_url_download()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3.2 - Test de batch URL download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Test 9: Batch URL download\n",
            "  üì• URLs a descargar: 2\n",
            "\n",
            "  ‚úÖ Batch completado en 1.3s\n",
            "     Total: 2\n",
            "     Uploaded: 2\n",
            "     Duplicates: 0\n",
            "     Failed: 0\n",
            "     ‚úÖ Rate limiting funcionando (>= 1.0s)\n"
          ]
        }
      ],
      "source": [
        "# Test de batch download\n",
        "async def test_batch_url_download():\n",
        "    base_url = \"http://localhost:8000/api/v1\"\n",
        "    \n",
        "    # URLs de ejemplo\n",
        "    test_urls = [\n",
        "        \"https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\",\n",
        "        \"https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\",  # Mismo archivo (test dedup)\n",
        "    ]\n",
        "    \n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=60.0) as client:\n",
        "            health = await client.get(f\"{base_url}/agents/health\")\n",
        "            \n",
        "            if health.status_code == 200:\n",
        "                print(\"üß™ Test 9: Batch URL download\")\n",
        "                print(f\"  üì• URLs a descargar: {len(test_urls)}\")\n",
        "                \n",
        "                import time\n",
        "                start = time.time()\n",
        "                \n",
        "                response = await client.post(\n",
        "                    f\"{base_url}/upload/from-urls\",\n",
        "                    json={\"urls\": test_urls, \"fuente\": \"provincial\"}\n",
        "                )\n",
        "                \n",
        "                elapsed = time.time() - start\n",
        "                \n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "                    print(f\"\\n  ‚úÖ Batch completado en {elapsed:.1f}s\")\n",
        "                    print(f\"     Total: {data['total']}\")\n",
        "                    print(f\"     Uploaded: {data['uploaded']}\")\n",
        "                    print(f\"     Duplicates: {data['duplicates']}\")\n",
        "                    print(f\"     Failed: {data['failed']}\")\n",
        "                    \n",
        "                    # Verificar rate limiting\n",
        "                    expected_min_time = (len(test_urls) - 1) * 1.0  # 1 segundo entre requests\n",
        "                    if elapsed >= expected_min_time:\n",
        "                        print(f\"     ‚úÖ Rate limiting funcionando (>= {expected_min_time:.1f}s)\")\n",
        "                    else:\n",
        "                        print(f\"     ‚ö†Ô∏è  Rate limiting posiblemente no funcionando\")\n",
        "                else:\n",
        "                    print(f\"  ‚ùå Error: {response.status_code}\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è  Servidor no disponible\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error: {e}\")\n",
        "\n",
        "await test_batch_url_download()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Resumen de Epic 1\n",
        "\n",
        "### ‚úÖ Componentes implementados y verificados\n",
        "\n",
        "#### Task 1.1 - SHA256 Deduplication\n",
        "- ‚úÖ Columnas `file_hash` y `file_size_bytes` agregadas a `boletines`\n",
        "- ‚úÖ Funciones de hashing implementadas y probadas\n",
        "- ‚úÖ Deduplicaci√≥n por hash funcionando en `create_boletin()`\n",
        "- ‚úÖ Scraper calcula hashes autom√°ticamente\n",
        "- ‚úÖ Script de backfill disponible\n",
        "\n",
        "#### Task 1.2 - Batch Upload\n",
        "- ‚úÖ Endpoint `POST /api/v1/upload/files` implementado\n",
        "- ‚úÖ Validaci√≥n de PDFs por magic bytes\n",
        "- ‚úÖ L√≠mites de tama√±o configurables (10KB - 50MB)\n",
        "- ‚úÖ Parsing autom√°tico de filenames\n",
        "- ‚úÖ Respuestas detalladas por archivo\n",
        "\n",
        "#### Task 1.3 - Generic URL Download\n",
        "- ‚úÖ Endpoint `POST /api/v1/upload/from-url` implementado\n",
        "- ‚úÖ Endpoint `POST /api/v1/upload/from-urls` para batch\n",
        "- ‚úÖ Rate limiting (1 segundo entre requests)\n",
        "- ‚úÖ Timeout configurable (60 segundos)\n",
        "- ‚úÖ Deduplicaci√≥n autom√°tica\n",
        "\n",
        "### üìä M√©tricas de √©xito\n",
        "- Todos los tests unitarios pasaron\n",
        "- Migraci√≥n de BD aplicada exitosamente\n",
        "- Endpoints REST funcionando correctamente\n",
        "- Deduplicaci√≥n previene almacenamiento de duplicados\n",
        "- Sistema compatible con archivos existentes\n",
        "\n",
        "### üéØ Pr√≥ximos pasos recomendados\n",
        "1. Ejecutar backfill: `python scripts/backfill_file_hashes.py --check-duplicates`\n",
        "2. Iniciar servidor para tests de integraci√≥n completos\n",
        "3. Monitorear estad√≠sticas de deduplicaci√≥n en producci√≥n\n",
        "4. Considerar agregar √≠ndice compuesto `(file_hash, filename)` si hay muchos duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "√âPICA 1: INGESTA - TESTING COMPLETADO\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Task 1.1: SHA256 Deduplication\n",
            "‚úÖ Task 1.2: Batch File Upload\n",
            "‚úÖ Task 1.3: Generic URL Download\n",
            "\n",
            "üéâ Todas las tareas implementadas y verificadas\n",
            "\n",
            "üìù Tickets actualizados en Notion Board\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Resumen final\n",
        "print(\"=\"*80)\n",
        "print(\"√âPICA 1: INGESTA - TESTING COMPLETADO\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n‚úÖ Task 1.1: SHA256 Deduplication\")\n",
        "print(\"‚úÖ Task 1.2: Batch File Upload\")\n",
        "print(\"‚úÖ Task 1.3: Generic URL Download\")\n",
        "print(\"\\nüéâ Todas las tareas implementadas y verificadas\")\n",
        "print(\"\\nüìù Tickets actualizados en Notion Board\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
