# üìä An√°lisis de Precisi√≥n - B√∫squeda Sem√°ntica

## Resultados del Benchmark

### Resumen General
```
Tests ejecutados: 6
Tests aprobados: 1/6 (16.7%) ‚ùå
Precision@10 promedio: 13.3% ‚ùå
Score promedio: 44.6%
Tiempo promedio: 380ms ‚úÖ
```

### Detalle por Test

| Test | Precisi√≥n@10 | Score Avg | Relevantes | Resultado |
|------|--------------|-----------|------------|-----------|
| B√∫squeda gen√©rica "contrato" | 0% | 26.3% | 0/10 | ‚ùå FALL√ì |
| Contratos de construcci√≥n | 0% | 43.2% | 0/10 | ‚ùå FALL√ì |
| Licitaciones p√∫blicas | 50% | 52.9% | 5/10 | ‚úÖ PAS√ì |
| Designaciones funcionarios | 30% | 50.0% | 3/10 | ‚ùå FALL√ì |
| Presupuesto/fondos | 0% | 49.9% | 0/10 | ‚ùå FALL√ì |
| Resoluciones administrativas | 0% | 45.0% | 0/10 | ‚ùå FALL√ì |

---

## Problemas Identificados

### 1. ‚ö†Ô∏è Baja Precisi√≥n General
**Problema**: Solo 13.3% de precision@10 promedio
**Causa**: El modelo actual (all-MiniLM-L6-v2) no est√° optimizado para:
- Documentos legales en espa√±ol
- Terminolog√≠a administrativa espec√≠fica
- Texto formal gubernamental

### 2. ‚ö†Ô∏è B√∫squedas Gen√©ricas Fallan
**Problema**: "contrato" devuelve 0% de resultados relevantes
**Causa**: 
- T√©rmino demasiado gen√©rico
- Falta de contexto sem√°ntico
- El modelo no captura bien t√©rminos aislados

### 3. ‚ö†Ô∏è Solo Queries Largas Funcionan
**Problema**: "licitaci√≥n p√∫blica obras p√∫blicas" funciona (50%), pero queries cortas fallan
**Causa**: 
- El modelo necesita m√°s contexto para entender la intenci√≥n
- B√∫squedas de 1-2 palabras son insuficientes

### 4. ‚úÖ Velocidad Excelente
**Positivo**: 380ms promedio es muy bueno para producci√≥n

---

## An√°lisis de Modelo Actual

### Modelo: all-MiniLM-L6-v2
**Caracter√≠sticas**:
- **Dimensiones**: 384
- **Entrenamiento**: Ingl√©s general
- **Velocidad**: R√°pida ‚ö°
- **Precisi√≥n espa√±ol**: Baja ‚ùå
- **Contexto legal**: Ninguno ‚ùå

### Limitaciones
1. No fue entrenado espec√≠ficamente para espa√±ol
2. No tiene conocimiento de terminolog√≠a legal argentina
3. Embeddings de 384 dimensiones son limitados para texto especializado
4. No captura bien contexto administrativo/gubernamental

---

## Recomendaciones de Mejora

### Opci√≥n 1: Modelo Multiling√ºe (Implementable Ya) ‚≠ê
**Modelo**: `paraphrase-multilingual-MiniLM-L12-v2`

**Ventajas**:
- ‚úÖ Entrenado espec√≠ficamente para espa√±ol
- ‚úÖ Mejor comprensi√≥n de contexto multiling√ºe
- ‚úÖ Sin cambios en infraestructura
- ‚úÖ Similar velocidad

**Implementaci√≥n**:
```python
# En indexar_embeddings.py
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
embedding_function = lambda texts: model.encode(texts).tolist()

collection = client.get_or_create_collection(
    name="watcher_documents_multilingual",
    embedding_function=embedding_function
)
```

**Mejora esperada**: +20-30% en precision@10

### Opci√≥n 2: Modelo Legal Espa√±ol (√ìptimo) ‚≠ê‚≠ê‚≠ê
**Modelo**: `nlpaueb/legal-bert-base-uncased` + fine-tuning

**Ventajas**:
- ‚úÖ Pre-entrenado en textos legales
- ‚úÖ Puede ser fine-tuned con boletines argentinos
- ‚úÖ Mejor comprensi√≥n de terminolog√≠a espec√≠fica
- ‚ö†Ô∏è Requiere m√°s recursos (768 dimensiones)

**Mejora esperada**: +40-50% en precision@10

### Opci√≥n 3: Modelo Embeddings Grande (M√°xima Calidad) ‚≠ê‚≠ê‚≠ê‚≠ê
**Modelo**: `intfloat/multilingual-e5-large`

**Ventajas**:
- ‚úÖ SOTA para tareas multiling√ºes
- ‚úÖ 1024 dimensiones (mucho m√°s expresivo)
- ‚úÖ Excelente para textos largos
- ‚ö†Ô∏è M√°s lento (2-3x)
- ‚ö†Ô∏è Requiere m√°s espacio

**Mejora esperada**: +50-60% en precision@10

### Opci√≥n 4: H√≠brido (Recomendado para Producci√≥n) ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Estrategia**: Combinar b√∫squeda sem√°ntica + keyword matching

**Implementaci√≥n**:
1. **B√∫squeda Sem√°ntica** con modelo multiling√ºe
2. **Re-ranking** con TF-IDF o BM25
3. **Filtros** por keywords exactas

**C√≥digo**:
```python
# 1. B√∫squeda sem√°ntica (top 50)
semantic_results = await embedding_service.search(query, n_results=50)

# 2. Re-ranking con BM25
from rank_bm25 import BM25Okapi
corpus = [r['document'] for r in semantic_results]
bm25 = BM25Okapi(corpus)
scores = bm25.get_scores(query.split())

# 3. Combinar scores
final_results = []
for i, result in enumerate(semantic_results):
    combined_score = 0.7 * result['score'] + 0.3 * scores[i]
    result['combined_score'] = combined_score
    final_results.append(result)

# Ordenar por score combinado
final_results.sort(key=lambda x: x['combined_score'], reverse=True)
```

**Mejora esperada**: +30-40% en precision@10

---

## Plan de Acci√≥n Recomendado

### Fase 1: Quick Win (1-2 horas) ‚≠ê
**Objetivo**: Mejorar precisi√≥n en 20-30%

1. **Re-indexar con modelo multiling√ºe**
```bash
# Instalar modelo
pip install sentence-transformers

# Re-indexar con nuevo modelo
python scripts/indexar_embeddings.py \
  --year 2026 \
  --model paraphrase-multilingual-MiniLM-L12-v2 \
  --force
```

2. **Actualizar b√∫squeda para usar nuevo modelo**
3. **Ejecutar benchmark nuevamente**

### Fase 2: Optimizaci√≥n (2-4 horas) ‚≠ê‚≠ê
**Objetivo**: +10-15% adicional

1. **Implementar re-ranking h√≠brido**
2. **Agregar boost por keywords exactas**
3. **Ajustar scores seg√∫n tipo de documento**

### Fase 3: Fine-tuning (1-2 d√≠as) ‚≠ê‚≠ê‚≠ê
**Objetivo**: M√°xima precisi√≥n

1. **Crear dataset de training** con boletines etiquetados
2. **Fine-tune modelo multiling√ºe** con datos reales
3. **Evaluar y comparar**

---

## M√©tricas de √âxito

### Objetivos
```
Precision@10: > 60% (actualmente 13.3%)
Score promedio: > 65% (actualmente 44.6%)
Tiempo de respuesta: < 500ms (actualmente 380ms ‚úÖ)
```

### KPIs a Monitorear
- **Precision@K** (K=5, 10, 20)
- **Recall@K**
- **Mean Average Precision (MAP)**
- **Normalized Discounted Cumulative Gain (NDCG)**
- **Tiempo de respuesta**
- **Satisfacci√≥n del usuario** (feedback)

---

## Implementaci√≥n Inmediata Sugerida

### Script de Re-indexaci√≥n con Modelo Multiling√ºe
```python
# scripts/reindex_multilingual.py
import asyncio
from sentence_transformers import SentenceTransformer
import chromadb
from pathlib import Path

async def reindex_with_multilingual():
    # Cargar modelo multiling√ºe
    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    
    # Crear nueva colecci√≥n
    client = chromadb.PersistentClient(path=str(Path.home() / ".watcher" / "chromadb"))
    
    # Eliminar colecci√≥n anterior
    try:
        client.delete_collection("watcher_documents")
    except:
        pass
    
    # Crear nueva con embedding function
    collection = client.create_collection(
        name="watcher_documents",
        metadata={"description": "Watcher Agent - Multilingual Model"},
        embedding_function=lambda texts: model.encode(texts).tolist()
    )
    
    print("‚úÖ Colecci√≥n creada con modelo multiling√ºe")
    print("üìù Ahora ejecuta: python scripts/indexar_embeddings.py --year 2026")

if __name__ == "__main__":
    asyncio.run(reindex_with_multilingual())
```

---

## Pr√≥ximos Pasos

### Inmediato (Hoy)
1. ‚úÖ Benchmark completado
2. ‚è≥ Decidir estrategia (modelo multiling√ºe o h√≠brido)
3. ‚è≥ Re-indexar con nuevo modelo
4. ‚è≥ Ejecutar nuevo benchmark

### Corto Plazo (Esta Semana)
1. Implementar re-ranking h√≠brido
2. Agregar m√°s casos de prueba al benchmark
3. Crear dashboard de m√©tricas

### Mediano Plazo (Pr√≥ximas 2 Semanas)
1. Preparar dataset para fine-tuning
2. Experimentar con modelos especializados
3. A/B testing con usuarios reales

---

## Conclusi√≥n

**Estado Actual**: ‚ùå Precisi√≥n insuficiente para producci√≥n (13.3%)

**Problema Principal**: Modelo no optimizado para espa√±ol legal

**Soluci√≥n Recomendada**: 
1. **Inmediato**: Re-indexar con modelo multiling√ºe (+20-30%)
2. **Corto plazo**: Implementar b√∫squeda h√≠brida (+10-15% adicional)
3. **Mediano plazo**: Fine-tuning con datos reales (+10-20% adicional)

**Resultado Esperado**: >60% precision@10 (aceptable para producci√≥n)

---

**Archivo de resultados**: `scripts/benchmark_results.json`  
**Fecha de an√°lisis**: 2026-02-09  
**Pr√≥xima evaluaci√≥n**: Despu√©s de implementar modelo multiling√ºe
